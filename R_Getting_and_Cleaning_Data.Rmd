---
title: "R Notebook - Getting and Cleaning Data"
output: 
  html_notebook:
    toc: TRUE
    toc_float: TRUE
    theme: united
author: Jason Seto

---
This notebook was created to work through the examples and problems for getting and cleaning data

#Week
##Lesson
###Slide

---

#Week 1

##Reading XML

install.packages("XML")

```{r}
library(XML)
```

You can pull XML using the XML package in R. The code below accesses the w3schools site and pulls the breakfast node from the XML

1. Load the package
2. Give it a URL
3. Load it into R Memory
4. Rootnode -- the wrapper element for the entire document

```{r}
fileurl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileurl,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
```

This tells us that we get five different names in the rootnote (all related to food)
```{r}
names(rootNode)
```

###Directly access parts of the XML

If I want to pull the first food element

```{r}
rootNode[[1]]
```

Now if I want to keep drilling down, you can just subset by adding an additional element (in this case 1)

```{r}
rootNode[[1]][[1]]
```

###Programatically extract various parts of the xml

```{r tidy=TRUE} 
xmlSApply(rootNode,xmlValue)
```

###XPath

If you want to extract some of the XML document you can use the XPath language

Link: www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf

Some basic commands:

XPath                   Description
------------            ------------
/node                   Top Level Node
//node                  Node at any level
node[@attr_name]        Node with any attribute name
node[@attr-name='bob']  Node with attribute name attr-name = bob


###Get Items and menu prices

The xpathSApply command pulls from:

* rootnode - The whole XML
* //name   - which is the node with the "Name" header
* xmlvalue - the type of data you are pulling

```{r}
xpathSApply(rootNode,"//name", xmlValue)
```

Now try the same thing for price

```{r}
xpathSApply(rootNode,"//price", xmlValue)
```

###ESPN Page

http://www.espn.com/nfl/team/_/name/bal/baltimore-ravens

1. Right click on page
2. View Source
3. It's an extensive HTML

* Trying to pull scores against different teams

1. Load URL
2. Parse as HTML (note that it's slightly different from XML and you can see HTML at the top)
3. Use the xPathSApply to pull out 

```{r}
fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileUrl, useInternal = TRUE)
scores <- xpathSApply(doc, "//li[@class='score']", xmlValue)
teams <- xpathSApply(doc, "//li[@class='team-name']", xmlValue)

scores
teams
```


```{r}
a <- "http://sports.yahoo.com/nfl/scoreboard/"
b <- htmlTreeParse(fileURL, useInternalNodes =TRUE)
scores <- xpathSApply(doc, "//li[@id='scoreboard-group-2']",class="score")
scores
```

//*[@id="scoreboard-group-2"]/div/ul/li[1]/div/a/div/div[2]/div[1]/ul/li[2]/div[2]/div/span[1]

## Reading in JSON

Javascript Object Notation

* Lightweight data storage language
* Data stored as numbers, strings, booleans, and objects

https://api.github.com/users/jtleek/repos


### JsonLite
install.packages("httr")
library(httr)
set_config(config(ssl_verifypeer = 0L))

```{r}
library(jsonlite)
```

jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)
